"""
Script de scraping unique pour la page Facebook Fasopresse
RÃ©cupÃ¨re les posts et les sauvegarde dans un fichier JSON
"""

import json
import os
from datetime import datetime
from dotenv import load_dotenv
from facebook_playwright_scraper import FacebookPlaywrightScraper

# Charger les variables d'environnement
load_dotenv()


def scrape_fasopresse_once(email: str, password: str, max_posts: int = 50):
    """
    Effectue un scraping unique de la page Fasopresse
    
    Args:
        email: Email Facebook
        password: Mot de passe Facebook
        max_posts: Nombre maximum de posts Ã  rÃ©cupÃ©rer
    """
    print("\n" + "="*70)
    print("ğŸš€ SCRAPING FASOPRESSE - EXÃ‰CUTION UNIQUE")
    print("="*70)
    
    # URL de la page Fasopresse
    page_url = "https://web.facebook.com/p/Fasopresse-Lactualit%C3%A9-du-Burkina-Faso-100067981629793/"
    
    # Mots-clÃ©s pour valider les URLs
    page_keywords = ['fasopresse', 'Fasopresse', 'p/Fasopresse']
    
    # CrÃ©er le scraper
    scraper = FacebookPlaywrightScraper(headless=False, page_keywords=page_keywords)
    
    print(f"ğŸŒ Page cible: {page_url}")
    print(f"ğŸ“Š Posts max: {max_posts}")
    print(f"ğŸ”‘ Mots-clÃ©s: {', '.join(page_keywords)}")
    print("="*70 + "\n")
    
    # Scraper la page
    posts = scraper.scrape_page(
        page_url=page_url,
        email=email,
        password=password,
        max_posts=max_posts
    )
    
    if not posts:
        print("\nâŒ Aucun post rÃ©cupÃ©rÃ©")
        return
    
    # Calculer les statistiques
    total_engagement = sum(p['engagement_total'] for p in posts)
    total_likes = sum(p['likes'] for p in posts)
    total_comments = sum(p['comments'] for p in posts)
    total_shares = sum(p['shares'] for p in posts)
    
    # PrÃ©parer les donnÃ©es
    output = {
        'posts': posts,
        'metadata': {
            'total_posts': len(posts),
            'scrape_date': datetime.now().isoformat(),
            'total_engagement': total_engagement,
            'total_likes': total_likes,
            'total_comments': total_comments,
            'total_shares': total_shares,
            'page': 'Fasopresse',
            'page_url': page_url
        }
    }
    
    # Sauvegarder dans un fichier JSON
    filename = 'fasopresse_posts.json'
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)
    
    print(f"\n{'='*70}")
    print(f"âœ… SCRAPING TERMINÃ‰")
    print(f"{'='*70}")
    print(f"ğŸ“ Fichier: {filename}")
    print(f"ğŸ“Š Posts rÃ©cupÃ©rÃ©s: {len(posts)}")
    print(f"ğŸ’¬ Engagement total: {total_engagement:,}")
    print(f"  ğŸ‘ Likes: {total_likes:,}")
    print(f"  ğŸ’¬ Commentaires: {total_comments:,}")
    print(f"  ğŸ”„ Partages: {total_shares:,}")
    print(f"{'='*70}\n")
    
    # Pas besoin de fermer le scraper, il se ferme automatiquement aprÃ¨s scrape_page


def main():
    """Point d'entrÃ©e principal"""
    # RÃ©cupÃ©rer les credentials depuis les variables d'environnement
    email = os.getenv('FACEBOOK_EMAIL')
    password = os.getenv('FACEBOOK_PASSWORD')
    
    if not email or not password:
        print("âŒ ERREUR: Variables d'environnement manquantes!")
        print("CrÃ©ez un fichier .env avec:")
        print("FACEBOOK_EMAIL=votre_email")
        print("FACEBOOK_PASSWORD=votre_mot_de_passe")
        return
    
    # Lancer le scraping
    scrape_fasopresse_once(
        email=email,
        password=password,
        max_posts=50
    )


if __name__ == "__main__":
    main()
