"""
Script de monitoring temps rÃ©el de la page Facebook ESidwaya
DÃ©tecte le dernier post et met Ã  jour les mÃ©triques dans un JSON (pas de doublons)
"""

import json
import time
import os
from datetime import datetime
from dotenv import load_dotenv
from facebook_playwright_scraper import FacebookPlaywrightScraper

# Charger les variables d'environnement
load_dotenv()


class ESidwayaRealtimeMonitor:
    """Moniteur temps rÃ©el pour ESidwaya avec export JSON"""
    
    def __init__(self, check_interval: int = 600):
        """
        Initialise le moniteur
        
        Args:
            check_interval: Intervalle de vÃ©rification en secondes (600s = 10min)
        """
        self.check_interval = check_interval
        self.json_filename = 'esidwaya_realtime.json'
        self.posts_dict = {}  # Dict pour accÃ¨s rapide par post_id
        self.page_keywords = ['ESidwaya', 'sidwaya', '100064709527661']
        self.scraper = None
        self.is_logged_in = False
        
    def load_existing_data(self):
        """Charge les donnÃ©es existantes depuis le JSON"""
        if not os.path.exists(self.json_filename):
            print(f"ğŸ“„ Nouveau fichier JSON Ã  crÃ©er: {self.json_filename}")
            return
        
        try:
            with open(self.json_filename, 'r', encoding='utf-8') as f:
                data = json.load(f)
                posts = data.get('posts', [])
                for post in posts:
                    self.posts_dict[post['post_id']] = post
            print(f"ğŸ“‚ {len(self.posts_dict)} posts chargÃ©s depuis JSON")
        except Exception as e:
            print(f"âš ï¸ Erreur chargement JSON: {e}")
    
    def save_to_json(self):
        """Sauvegarde toutes les donnÃ©es dans le JSON"""
        try:
            # Trier par date (plus rÃ©cent d'abord)
            sorted_posts = sorted(self.posts_dict.values(), 
                                key=lambda x: x['date_post'], 
                                reverse=True)
            
            # Calculer les statistiques
            total_engagement = sum(p['engagement_total'] for p in sorted_posts)
            total_likes = sum(p['likes'] for p in sorted_posts)
            total_comments = sum(p['comments'] for p in sorted_posts)
            total_shares = sum(p['shares'] for p in sorted_posts)
            
            output = {
                'posts': sorted_posts,
                'metadata': {
                    'total_posts': len(sorted_posts),
                    'last_update': datetime.now().isoformat(),
                    'total_engagement': total_engagement,
                    'total_likes': total_likes,
                    'total_comments': total_comments,
                    'total_shares': total_shares,
                    'page': 'ESidwaya',
                    'page_url': 'https://web.facebook.com/ESidwaya'
                }
            }
            
            with open(self.json_filename, 'w', encoding='utf-8') as f:
                json.dump(output, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ {len(self.posts_dict)} posts sauvegardÃ©s dans {self.json_filename}")
        except Exception as e:
            print(f"âŒ Erreur sauvegarde JSON: {e}")
    
    def check_and_update(self, email: str, password: str, page_url: str):
        """
        VÃ©rifie le dernier post et met Ã  jour les mÃ©triques de tous les posts
        """
        print(f"\n{'='*70}")
        print(f"ğŸ” VÃ‰RIFICATION - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'='*70}")
        
        # Initialiser le scraper si nÃ©cessaire
        if not self.scraper:
            self.scraper = FacebookPlaywrightScraper(headless=True, page_keywords=self.page_keywords)
        
        # Scraper la page (rÃ©cupÃ¨re 50 posts max)
        if not self.is_logged_in:
            print("ğŸ” Connexion initiale...")
        else:
            print("â™»ï¸ RÃ©utilisation de la session...")
        
        self.scraper.scrape_page(page_url, email, password, max_posts=50)
        self.is_logged_in = True
        
        if not self.scraper.posts_data:
            print("âš ï¸ Aucun post rÃ©cupÃ©rÃ©")
            return
        
        # DÃ©tecter le dernier post (le plus rÃ©cent)
        latest_post = self.scraper.posts_data[0]  # Le premier est le plus rÃ©cent
        
        # Statistiques
        new_posts = 0
        updated_posts = 0
        
        # Traiter tous les posts scrapÃ©s
        for post in self.scraper.posts_data:
            post_id = post['post_id']
            
            if post_id not in self.posts_dict:
                # Nouveau post dÃ©tectÃ©
                self.posts_dict[post_id] = {
                    'post_id': post_id,
                    'url': post['url'],
                    'date_post': post['date_post'],
                    'contenu': post['contenu'],
                    'likes': post['likes'],
                    'comments': post['comments'],
                    'shares': post['shares'],
                    'engagement_total': post['engagement_total'],
                    'commentaires': post.get('commentaires', []),
                    'last_update': datetime.now().isoformat()
                }
                new_posts += 1
                
                print(f"\nğŸ†• NOUVEAU POST dÃ©tectÃ©:")
                print(f"   ğŸ“ {post['contenu'][:100]}...")
                print(f"   ğŸ‘ {post['likes']} likes | ğŸ’¬ {post['comments']} comments | ğŸ”„ {post['shares']} shares")
            
            else:
                # Post existant - vÃ©rifier si les mÃ©triques ont changÃ©
                old_post = self.posts_dict[post_id]
                
                if (old_post['likes'] != post['likes'] or 
                    old_post['comments'] != post['comments'] or 
                    old_post['shares'] != post['shares']):
                    
                    # Mise Ã  jour
                    old_engagement = old_post['engagement_total']
                    new_engagement = post['engagement_total']
                    
                    self.posts_dict[post_id].update({
                        'likes': post['likes'],
                        'comments': post['comments'],
                        'shares': post['shares'],
                        'engagement_total': post['engagement_total'],
                        'commentaires': post.get('commentaires', []),
                        'last_update': datetime.now().isoformat()
                    })
                    updated_posts += 1
                    
                    print(f"\nğŸ”„ POST MIS Ã€ JOUR:")
                    print(f"   ğŸ“ {post['contenu'][:60]}...")
                    print(f"   ğŸ‘ {old_post['likes']} â†’ {post['likes']} (+{post['likes'] - old_post['likes']})")
                    print(f"   ğŸ’¬ {old_post['comments']} â†’ {post['comments']} (+{post['comments'] - old_post['comments']})")
                    print(f"   ğŸ”„ {old_post['shares']} â†’ {post['shares']} (+{post['shares'] - old_post['shares']})")
                    print(f"   ğŸ“Š Engagement: {old_engagement} â†’ {new_engagement}")
        
        # Sauvegarder dans le JSON
        self.save_to_json()
        
        # RÃ©sumÃ©
        print(f"\n{'='*70}")
        print(f"ğŸ“Š RÃ‰SUMÃ‰:")
        print(f"   ğŸ†• Nouveaux posts: {new_posts}")
        print(f"   ğŸ”„ Posts mis Ã  jour: {updated_posts}")
        print(f"   ğŸ“ Total posts suivis: {len(self.posts_dict)}")
        
        # Info sur le dernier post
        if latest_post['post_id'] in self.posts_dict:
            latest = self.posts_dict[latest_post['post_id']]
            print(f"\nğŸ¯ DERNIER POST:")
            print(f"   ğŸ“ {latest['contenu'][:100]}...")
            print(f"   ğŸ‘ {latest['likes']} | ğŸ’¬ {latest['comments']} | ğŸ”„ {latest['shares']} = ğŸ“Š {latest['engagement_total']}")
        
        print(f"{'='*70}\n")
    
    def start_monitoring(self, email: str, password: str, page_url: str):
        """
        Lance le monitoring en temps rÃ©el
        """
        print("=" * 70)
        print("ğŸš€ DÃ‰MARRAGE DU MONITORING TEMPS RÃ‰EL - ESIDWAYA")
        print("=" * 70)
        print(f"ğŸ“ Page: {page_url}")
        print(f"â±ï¸ Intervalle: {self.check_interval}s ({self.check_interval//60} min)")
        print(f"ğŸ’¾ Fichier JSON: {self.json_filename}")
        print("=" * 70)
        
        # Charger les donnÃ©es existantes
        self.load_existing_data()
        
        # PremiÃ¨re vÃ©rification immÃ©diate
        print("\nğŸ” PremiÃ¨re vÃ©rification...")
        self.check_and_update(email, password, page_url)
        
        # Boucle de monitoring
        try:
            iteration = 1
            while True:
                print(f"\nâ³ Prochaine vÃ©rification dans {self.check_interval}s...")
                print(f"   (Ctrl+C pour arrÃªter)")
                time.sleep(self.check_interval)
                
                iteration += 1
                print(f"\nğŸ“… ItÃ©ration #{iteration}")
                self.check_and_update(email, password, page_url)
                
        except KeyboardInterrupt:
            print("\n\nâ¹ï¸ ArrÃªt du monitoring...")
            print(f"ğŸ’¾ DerniÃ¨re sauvegarde...")
            self.save_to_json()
            print("âœ… Monitoring arrÃªtÃ© proprement")


def main():
    """Fonction principale"""
    # Configuration
    email = os.getenv('FB_EMAIL')
    password = os.getenv('FB_PASSWORD')
    page_url = 'https://web.facebook.com/ESidwaya'
    check_interval = int(os.getenv('CHECK_INTERVAL', '600'))  # 10 minutes par dÃ©faut
    
    if not email or not password:
        print("âŒ Erreur: Identifiants manquants dans le fichier .env")
        return
    
    # CrÃ©er et lancer le moniteur
    monitor = ESidwayaRealtimeMonitor(check_interval=check_interval)
    monitor.start_monitoring(email, password, page_url)


if __name__ == "__main__":
    main()
